\documentclass[12pt]{report}

\usepackage[italian]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage[pdftex]{graphics}
\usepackage{graphicx}
\graphicspath{/home/paologio/Documenti/Università/Tesi/Malchiodi/ACSDI/Elaborato}
\usepackage{chngcntr}
\counterwithout{footnote}{chapter}
\usepackage{booktabs}
\usepackage{cite}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{bm}
\usepackage{mathtools}
\setlength
\fboxsep{0.25cm}
\usepackage[makeroom]{cancel} %\cancelto{\infty}{}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage[showframe=false]{geometry}
\usepackage{changepage}
\usepackage{pdfpages}

\begin{document}

\includepdf{Frontespizio_UniMi.pdf}

\tableofcontents

\linespread{1.4}\selectfont

\chapter*{Introduzione}
Negli ultimi anni, grazie anche ad un continuo miglioramento delle prestazioni computazionali delle macchine, è aumentato lo studio e l'utilizzo di algoritmi per l'apprendimento automatico (o machine learning). L'impiego che ne viene fatto è vasto; dalla sicurezza dei dati al trading finanziario, dal campo sanitario al processamento del linguaggio naturale. Con l'aumentare delle prestazioni di processori e le dimensioni della memoria di dispositivi mobili, questi algoritmi hanno cominciato ad essere eseguiti anche su dispositivi mobili e IoT; tutt'oggi infatti abbiamo negli smartphone dei programmi che, facendo uso dell'intelligenza artificiale, riescono ad esempio a classificare le immagini o a fare da assistente vocale interagendo con i comandi vocali dell'utente. 
In questo elaborato verrà preso in esame un particolare ramo del machine learning: le reti neurali artificiali per fare regressione. \\
Nel primo capitolo verrà spiegato cosa sia effettivamente una rete neurale cominciando presentandone degli accenni storici, fino ad arrivare ad illustrarne l'architettura e come vengono usate. Come si vedrà in questo capitolo un grande problema delle reti neurali è la quantità di memoria che viene richiesta per memorizzarne le strutture dati occorrenti al loro funzionamento. A tal proposito vengono proposti due algoritmi di compressione, di cui si parlerà nel secondo capitolo, per rimediare a tale problema. L'interrogativo a cui questo elaborato si pone di rispondere è infatti quanto l'azione di compressione delle reti possa inficiare sulla loro accuratezza delle previsioni, ed in merito a ciò il terzo capitolo riporta gli esperimenti di compressione effettuati su una rete che predice l'indice di inserimento di un elemento all'interno di una lista ordinata (problema del predecessore).

\chapter{Le reti neurali artificiali}

\section{Definizione e origini storiche}
L’intuizione di replicare l’attività neurale che avviene nel sistema nervoso centrale umano quando apprende risale agli inizi degli anni ‘40, quando venne teorizzato un primo modello di neurone da McCulloch e Pitts (1943) ~\cite{McCulloch}. Il parallelo è molto stretto: così come il compito di un neurone è quello di ricevere, elaborare e ritrasmettere impulsi elettrici all’interno del sistema nervoso cerebrale, quello di un neurone artificiale è ricevere un certo dato in input e attivarsi o meno a seguito della sua elaborazione.
È interessante notare che, a differenza di un classico software, la costruzione di un neurone artificiale non richiede la scrittura di un programma ma avviene a seguito di un processo assimilabile a quello di apprendimento ~\cite{Perceptron}. Inoltre, continuando l'analogia con il sistema nervoso centrale, non ci si è limitati ad usare un singolo neurone ma più neuroni e più strati di neuroni collegati tra loro: questo ha portato allo sviluppo delle reti neurali.

\section{Il neurone artificiale}
Il neurone artificiale, vedi Figura 1.1, è composto da:
\begin{itemize}
\item{input}: rappresentati da $x_1$, $x_2$, $\dots$, $x_n$, sono l'input che riceve il neurone
\item{pesi}: rappresentati da $w_1$, $w_2$, $\dots$, $w_n$, sono i pesi associati alle singole connessioni tra input e neurone
\item{$\Sigma$}: viene eseguito $\displaystyle{\sum_{i=1}^n x_i \times w_i}$
\item{funzione d'attivazione}: la sommatoria al passo precedente viene usato come argomento per la funzione d'attivazione
\item{output}: il risultato dei passaggi precedenti viene propagato in output stabilendo l'attivazione o meno del neurone
\end{itemize}

\begin{figure}
\begin{center}
\includegraphics[scale=0.75]{neurone_artificiale.png}
\caption{Immagine di un neurone artificiale}
\end{center}
\end{figure}

\section{Architettura di una rete neurale}
Come detto precedentemente, una volta costruito un neurone artificiale, il passo successivo è stato quello di usare più neuroni in modo da formarne degli strati e connettere più strati tra di loro.
Una rete, per essere definita tale, deve essere composta da almeno 3 strati, vedi Figura 1.2:
\begin{enumerate}
\item{input}
\item{hidden}
\item{output}
\end{enumerate}

\begin{figure}
\includegraphics[scale=0.5]{nn_arch.png}
\caption{Architettura rete neurale}
\end{figure}

Il ruolo dello strato di input è quello di ricevere le feature da elaborare, lo strato nascosto si occuperà di rendere il modello più espressivo a livello di risoluzione di problemi di apprendimento rispetto ad uno con un solo neurone. Infine lo strato di output dovrà predire il risultato in base all’input ricevuto.

Inoltre, in base a come i neuroni dei vari strati sono collegati tra loro si possono distinguere due configurazioni di rete come quella densamente connessa (fully connected) o convoluzionale (convolutional) usate principalmente per il riconoscimento di pattern in immagini: a differenza di quelle densamente connesse, i neuroni di uno strato sono collegati solo ad una piccola parte dello strato precedente ~\cite{Convolutional}

In questo elaborato ci si concentrerà sulla tipologia densamente connessa, in cui ogni neurone di uno strato sarà collegato ad ogni neurone del successivo.

\subsection{Componenti}
Come detto sopra, la rete è composta da strati; gli strati, a loro volta, sono un insieme di neuroni, ognuno dei quali ha associato un peso ($w$) per ogni collegamento in entrata e un bias ($b$). Questi sono stati impostati randomicamente, in un intervallo tra 0 e 1. Questi due sono gli unici parametri che, una volta inizializzati, vengono modificati automaticamente dalla rete durante il training. I restanti parametri, come il numero di neuroni in uno strato hidden o il numero di strati, rimangono tali durante tutte le fasi di addestramento del modello; inoltre l'approccio tipicamente usato per individuare tali parametri è quello empirico: questi prendono il nome di \textit{iperparametri}.


\section{Applicazioni}
Le reti neurali vengono impiegate nell’attività di previsione (regressione) o classificazione.
Nel primo caso rientrano, ad esempio, le previsioni di vendita: riuscire a prevedere il prezzo di un immobile in base a fattori che lo descrivono (i metri quadrati, il numero di stanze, la posizione centrale o meno in un centro abitato, ecc…) o prevedere l’andamento di un titolo azionario in borsa.
Altro problema è quello invece della classificazione: si richiede in questo caso che la rete, dato un oggetto, ne restituisca la classe di appartenenza; tipico esempio è quello della classificazione di numeri scritti a mano o, date una serie di immagini, riconoscere quelle in cui è presente un particolare soggetto.
In questo elaborato si andrà ad affrontare il problema legato alla regressione.

\section{Esecuzione di una rete feed-forward}
Le connessioni tra i neuroni di uno strato e quelli del successivo sono monodirezionali, configurazione che porta ad avere un grafo diretto e aciclico. Quindi il flusso di dati che scorre nella rete viaggia dallo strato di input a quello di output senza che ci siano loop, il che implica anche che non ci siano interazioni tra neuroni dello stesso strato e che il tempo necessario per far scorrere i dati da input a output è costante.

\subsection{Il calcolo tra strati}\label{feedforward}
Nell'implementazione pratica vengono usate delle matrici dei pesi per rappresentare le connessioni tra strati e dei vettori per rappresentare i valori di bias dei pesi . 
Siano 
\begin{itemize}
\item{$W_{ih}$} la matrice dei pesi di dimensione $r \times c$, dove r è il numero di neuroni in input e c il numero di neuroni dello strato hidden; ogni componente di questa matrice rappresenta il peso di una connessione tra un neurone dello strato input e uno dello strato hidden;
\item{$W_{ho}$} analogamente al punto precedente, la matrice dei pesi che rappresenta le connessioni tra strato hidden e output;
\item{$b_h$} il vettore colonna dei bias dello strato hidden di dimensione $r \times 1$ dove r è il numero di neuroni dello strato hidden; ogni componente rappresenta il bias di uno dei neuroni dello strato hidden;
\item{$b_o$} analogamente al punto precedente, il vettore dei bias dello strato di output;
\item{$x$} il vettore di input;
\item{$f$} la funzione d'attivazione scelta per lo strato.
\end{itemize}
Per eseguire l'algoritmo di feed-forward occorre calcolare
$$\alpha = f\left(x \cdot W_{ih} + b_h\right),$$
procedendo poi analogamente con lo strato successivo
$$\mathrm{prediction} = f\left(\alpha \cdot W_{ho} + b_o\right).$$
Le reti considerate in questo lavoro vengono utilizzate per calcolare una regressione, e dunque hanno un solo neurone di output: prediction sarà quindi un valore scalare che rappresenterà la previsione della rete in base all'input ricevuto.

\section{Addestramento di una rete neurale}
Per continuare il parallelo con il sistema nervoso centrale umano, così come per l'attività di apprendimento occorre studiare, anche una rete neurale artificiale ha bisogno di ''studiare``: questa fase viene detta fase di addestramento (training).
Una volta selezionato il dataset contenente i caratteri che la rete dovrà apprendere, si procede a dividere tale insieme in due sottoinsiemi:

\begin{itemize}
\item{training set};
\item{testing set}.
\end{itemize}

Il primo verrà usato per l'attività di apprendimento, il secondo per valutare la bontà della rete su esempi che non ha ancora visto. Per selezionare la quantità di dati tra i due insiemi è stato utilizzato un holdout di 80\% - 20\%; una soluzione alternativa sarebbe stata quella di fare una cross-validation.

\subsection{Fase di training}
In questa fase le feature degli esempi nel training set vengono copiate nello strato di input della rete. Utilizzando la procedura descritta nel Paragrafo \ref{feedforward} la rete propaga il risultato fino al neurone di output. È in questo momento che la rete impara confrontando la previsione con l’effettivo target: in base alla loro differenza, la rete stessa correggerà i pesi degli strati usando un algoritmo noto come back-propagation (spiegato nel Paragrafo \ref{backprop}).
Questa operazione viene eseguita un numero n di volte, numero che prende il nome di epoca. Questo parametro indica che la rete ha visto tutti gli esempi del training set. Il concetto di epoca è strettamente legato a quello di batch size, iperparametro che specifica dopo ogni quanti esempi i pesi della rete verranno aggiornati.
Esempio: se avessi 200 esempi nel training set, batch size pari a 10 e 100 epoche significherebbe che in un epoca avverranno 20 aggiornamenti ($200 \div 10$) e al termine delle epoche 2000 aggiornamenti ($20 \times 100$).
Una volta che la rete ha iterato per un numero pari al numero di epoche scelto termina la fase di training.

Inoltre esistono diversi criteri per stabilire quando terminare l'apprendimento; in particolare negli esperimenti condotti in questo elaborato ne sono stati usati due basati su:
\begin{itemize}
\item{epoche}: il processo di apprendimento prosegue fino al raggiungimento del numero di epoche predefinito;
\item{valore della loss function}: vengono fissate due soglie, $s_1$ e $s_2$; l'apprendimento termina quando la loss function non supera $s_1$ per $s_2$ volte consecutive.
\end{itemize}

\subsection{Fase di testing}
Terminata la fase di training occorre verificare il comportamente della rete su dati nuovi rispetto a quelli usati per addestrarla. Questo permette di capire la reale capacità di previsione della rete e di valutare se durante l'addestramento si sia verificato uno dei problemi descritti di seguito.
\begin{itemize}
\item{Si parla di \textit{overfitting} quando il modello si adatta così tanto agli esempi del training set da perdere la capacità di generalizzare su nuovi esempi. Sintomo dell'overfitting è un'alta accuratezza durante la fase di training e una scarsa accuratezza in fase di testing; la rete ha imparato ''a memoria`` i casi di training in modo tale da non riconoscerne di nuovi};
\item{L'\textit{underfitting} è l'opposto del caso precedente. Si verifica quando il modello non riesce ad imparare la relazione tra feature e target, risultando in previsioni poco accurate}.
\end{itemize}

\section{Algoritmo di back-propagation}\label{backprop}
Una volta che l’informazione ha raggiunto lo strato di output ho la previsione; tuttavia questa conterrà dell’errore. Per ridurlo si usa un apposito algoritmo di propagazione all’indietro che regola i pesi associati ai collegamenti tra singoli neuroni, partendo dallo strato più esterno a quello più interno ~\cite{Backpropagation}. Quello che permette di fare è legare l'errore ottenuto in output a un algoritmo di ottimizzazione locale di una funzione di errore, in questo caso l'errore quadratico medio. Di seguito la formula per il calcolo dell'aggiornamento del peso.
$$W^n_x = W_x - \eta \left(\frac{\partial \mathrm{Error}}{\partial W_x}\right)$$ dove $W^n_x$ è il valore del nuovo peso, $W_x$ il vecchio peso, $\eta$ il learning rate e tra parentesi $\frac{\partial \mathrm{Error}}{\partial W_x}$ la derivata parziale dell'errore rispetto ai pesi e $\mathrm{Error}$ indica la funzione che associa a pesi e bias della rete l'errore corrispondente; la sua minimizzazione viene fatta usando l'algoritmo del gradiente discendente che consiste nel modificare i parametri della rete sottraendo loro una funzione del gradiente.

Una volta fatto questo calcolo con la matrice dei pesi strato hidden/output, si fa la stessa cosa per quella input/hidden.

\subsection{Iperparametri}\label{iperparametri}
Gli iperparametri sono tutti quelli il cui valore viene impostato prima che l'addestramento abbia inizio e che non cambiano nel corso dello stesso. Negli esperimenti presentati in questo elaborato questi valori vengono cercati empiricamente attraverso model selection (vedi \ref{modelselection})
In questa categoria rientrano:
\begin{itemize}
\item{learning rate}: indica il grado con cui la rete modifica i propri pesi durante la fase di back-propagation;
\item{numero di epoche}: indica il numero di volte che la rete ha visto tutti gli esempi del training set;
\item{batch size}: indica dopo quanti esempi mostrati alla rete si aggiornano i pesi;
\item{numero di neuroni per strato per strato nascosto}: indica il numero di neuroni per singolo strato;
\item{funzione d'attivazione}: funzione che determina l'intensità d'attivazione del singolo neurone.
\end{itemize}

Ogni volta che in questo elaborato verranno introdotti nuovi esperimenti ne verranno anche indicati gli iperparametri coinvolti.

\section{Model selection}\label{modelselection}
Come indicato nel paragrafo \ref{iperparametri}, per trovare il valore degli iperparametri bisogna basarsi su prove empiriche. In particolare, negli esperimenti condotti sono stati fissati a priori i valori per numero di epoche, batch size, numero di strati nascosti, learning rate e funzione d'attivazione. Il numero di neuroni dello strato nascosto è stato dimensionato usando una tecnica di model selection che prende il nome di cross-validation e che è spiegata nel prossimo paragrafo.

\subsection{Cross validation}\label{crossvalidation}
Dopo aver diviso il training set dal testing set, viene utilizzato esclusivamente  il primo per la cross-validation. In particolare questo viene partizionato in $k$ sottoinsiemi (fold) di cui uno di questi prenderà il nome di validation set e gli altri di training set. Per ogni valore possibile dell'iperparametro (o per ogni possibile configurazione se ci sono più iperparametri) vengono ripetuti $k$ processi di addestramento, ogni volta eliminando dal training set uno dei fold e utilizzando quet'ultimo per calcolare l'errore; si ottengono così $k$ errori di cui si calcola la media.

Es.: se il training set venisse suddviso in 3 fold le permutazioni prese in considerazione saranno:
\begin{enumerate}
\item{TRAINING | TRAINING | VALIDATION}
\item{TRAINING | VALIDATION | TRAINING}
\item{VALIDATION | TRAINING | TRAINING}
\end{enumerate}

Viene infine scelto il valore che corrisponde all'errore medio minore, e si riaddestra una rete dopo aver fissato a quel valore l'iperparametro.

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother

\begin{algorithm}
\caption{Cross Validation}
\begin{algorithmic}[1]
\Procedure{CrossValidation}{}
\BState \emph{input}:
\State $H \gets \textit{insieme di iperparametri presi in considerazione}$
\State $S \gets \textit{training set}$
\State $K \gets \textit{numero di fold}$
\BState \emph{procedure}:
\State $S_{perm} \gets \textit{K permutazioni di S}$
\State $L_M \gets [\infty] \;\forall\; h \;\in\; H$\\

\For {$k \in \{1,\dots,K\}$}
\State $s_{k} \gets \textit{k-esima permutazione di S}$

\For {$h \in H$}
\State $\textit{alleno la rete sul training set di } s_{k}$
\State $\textit{valuto la rete sul validation set di } s_{k}$
\State $L_{hk} \gets \textit{valore di loss per il k-esimo fold per h-esimo iperparametro}$
\State $L_M[h] \gets min(L_{hk}, \;L_M[h])$
\EndFor
\EndFor
\State $\textit{Per ogni iperparametro ho il carattere migliore dei k fold}$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\chapter{Algoritmi di compressione per reti neurali}

\section{Compressione di una rete}

Uno degli svantaggi più evidenti delle reti neurali è lo spazio che queste occupano in memoria e i tempi elevati per il loro l’addestramento. Questo aspetto ha assunto un ruolo sempre più importante con il diffondersi di macchine con ridotte capacità di computazione e di memoria e in generale dell’IoT. 
Per ridurre questo impatto negativo si stanno studiando diversi metodi per comprimere le strutture dati alla base di una rete neurale in modo da ridurne le dimensioni in memoria lasciando il più possibile invariata l’accuratezza. Questo elaborato si prefigge di verificare l'efficacia di due tecniche di compressione note come ''pruning`` e ''weight sharing`` su una rete neurale feed-forward utilizzata per problemi di regressione.

\section{Pruning}

L’idea di fondo del pruning è semplice: ogni collegamento tra neuroni ha associato un peso che ne determina l’importanza (avrà letteralmente un peso maggiore nell’influenzare il risultato finale della rete quando il valore della connessione è molto alto o molto basso), da qui l’intuizione per cui, ignorando i collegamenti con peso tendente allo zero, non altero significativamente il risultato della rete che otterrei considerandoli ~\cite{Pruning}.
Si sceglie quindi di annullare queste connessioni rendendo così sparsa la matrice dei pesi da memorizzare. Tuttavia questa operazione non è del tutto gratuita: ci si ritrova con nuove strutture dati per le quali è più lenta l'operazione di moltiplicazione tra matrici. Due scelte possibili per la struttura dati che accoglie la matrice sparsa sono indicate di seguito.
\begin{itemize}
\item{\textbf{\textit{Compressed Sparse Row}}} ~\cite{CSC}: vengono usati 3 vettori contenenti rispettivamente i valori non nulli della matrice letti riga per riga, gli indici di colonna e i puntatori ai primi valori non nulli delle righe descritti nel modo seguente: 

$$ptr =
\bigg \{
\begin{array}{ll}
ptr[0] = 0 \\
ptr[i] = prt[i - 1] - nz \\
\end{array}
$$
dove $nz$ è il numero di elementi non nulli nella riga $i - 1$;

\item{\textbf{\textit{Compressed Sparse Column}}}: simile alla precedente con la differenza che nel primo vettore i valori vengono letti per colonna, vengono memorizzati gli indici di riga per ogni valore e i relativi puntatori alle colonne.
\end{itemize}

Così facendo si può calcolare il tasso di compressione ottenuta mediante pruning; notando che quello che cambia è il numero di connessioni che vengono mantenute. Denotando quindi con $\tau$ la soglia, $s_c = \lbrace w_{ij} \,|\, w_{ij} \geq \tau \rbrace$ lo spazio occupato dalla rete compressa e $s$ lo spazio occupato dalla rete originale, la percentuale di memoria risparmiata può essere espressa tramite l'equazione \eqref{compressionRatio}

\begin{equation}
\mathrm{ratio} = \frac{s_c}{s}
\label{compressionRatio}
\end{equation}

In questo elaborato la soglia per scartare i pesi è stata calcolata come $n$-esimo percentile rispetto alla distribuzione dei pesi nella matrice, per $n \in \{10, \dots, 90 \}$ (quindi per $n=10$ verranno scartate il 10\% circa delle connessioni tra due strati comunicanti e così via).

\section{Weight Sharing}

La tecnica del weight sharing prende spunto dal flyweight pattern ~\cite{GOF}: questo è uno strumento di design software che permette di alleggerire la memoria utilizzata facendo condividere un oggetto usato da più istanze piuttosto che crearne più copie.
Nel caso pratico di una rete neurale gli oggetti da condividere sono i valori delle matrici dei pesi che vengono raggruppati in un singolo valore che riesca a rappresentarli adeguatamente. Questo valore prende il nome di centroide e verrà usato in sostituzione ai pesi raggruppati per le operazioni matriciali. 
Per stabilire i centroidi si possono usare algoritmi di clustering; in particolare quello usato in questo elaborato è K-Means ~\cite{KMeans}, che verrà spiegato nel dettaglio nel Paragrafo \ref{kmeans}. \\
Come strutture dati sono stati utilizzati un vettore per ogni strato in cui vengono memorizzati i centroidi come float 32 bit e una matrice in cui memorizzare l'indice del centroide relativo; gli indici sono rappresentati da interi a 16 bit se la dimensione della matrice è superiore a 256, altrimenti da interi a 8 bit. \\
Per gli esperimenti trattati nell'elaborato, dopo aver fissato il numero di clusters per strato e dopo averne trovato i centroidi, le matrici dei pesi sono state sostituite con le matrici di indici che puntano al relativo centroide. 

\subsection{Algoritmo K-Means}\label{kmeans}
L’algoritmo usato è quello della libreria sklearn, MiniBatchKMeans, che da documentazione segue l’euristica di Lloyd, descritta di seguita.

\begin{enumerate}
\item{Vengono scelti k centroidi casualmente, dove k è il numero di clusters che si vogliono creare}.
\item{Ogni osservazione viene assegnata ad uno dei centroidi in base alla distanza euclidea dello stesso}.
\item{I centroidi vengono aggiornati in base alla media dei valori rientranti nel cluster}.
\item{Se i centroidi sono stati aggiornati si ripete iterativamente dal punto 2, altrimenti l’algoritmo ha trovato i k centroidi}.
\end{enumerate}
 

\chapter{Esperimenti}

L'obiettivo di questo tirocinio è quello di verificare l'efficacia di tecniche di compressione su una rete neurale col compito di risolvere il problema del predecessore \ref{probPred}.
Si è deciso di cominciare focalizzandosi sul problema della regressione: è stato usato un dataset con informazioni relative alle caratteristiche dei giocatori di calcio Fifa 2019 \footnote{https://www.kaggle.com/karangadiya/fifa19, ultimo controllo ...} con l’obiettivo di predire il valore di mercato del giocatore. Due tipi differenti di reti sono state usate: la prima che sfrutta le API di Keras, la seconda creata ad hoc per essere successivamente compressa.

Una volta conclusa questa parte si è affrontato il problema della compressione per il problema del predecessore usando un dataset descritto nel dettaglio nel Paragrafo \ref{probPred}.

D'ora in poi si utlizzerà il termine feature per indicare una caratteristica che la rete usa durante la fase di training per predire il risultato e target per indicare il valore da predire in base alle feature in input.

\section{Dataset utilizzati}

\subsection{Fifa 2019}

Il primo dataset utilizzato è stato quello dei giocatori fifa, composto da 89 feature e circa 18.2k esempi. 
Una volta eliminate le feature non necessarie all’esperimento (nome del giocatore, immagine del club, numero di maglia, ecc… ) si è proceduto a convertire tutti i valori numerici rappresentati come stringhe (come “Value”, “Release clause”, “Height”, ecc…) in float e a rimuovere dal dataset tutti gli esempi il cui “Value” risultasse superiore o uguale al valore minimo tra gli outlier trovati. Inoltre i nomi delle squadre di appartenenza sono stati inclusi come feature significative e codificati in valori interi.

Terminata questa fase preliminare si è deciso di considerare diverse alternative: la prima in cui vengono considerate tutte le feature a disposizione, la seconda in cui vengono selezionate solamente quelle il cui indice di correlazione \footnote{Calcolato tramite il metodo corr di pandas che utilizza il coefficiente di correlazione di Pearson $\rho_{X,Y} = \frac{cov(X, Y)}{\sigma_X\sigma_Y}$ dove $cov$ è la covarianza, $\sigma_X$ la deviazione standard di X e $\sigma_Y$ la deviazione standard di Y} fosse maggiore di 0.55.
È stata considerata anche una terza opzione: selezionare la metà delle feature tramite la Principal Component Analysis (PCA) che permette di ridurre la cardinalità di un insieme di dati costituito da un elevato numero di variabili interconnesse, mantenendo il più possibile la variazione presente in esso ~\cite{PCA}. 

\subsection{Problema del predecessore}\label{probPred}
Se si vuole mantenere una lista di elementi ordinati per poi riuscire ad accedervi in poco tempo esistono delle strutture dati pensate apposta come ad esempio gli alberi binari bilanciati. Il tempo di accesso a queste strutture dati è dell'ordine di $O(log\,n)$, dove $n$ è il numero totale di elementi. Nonostante questo sia uno dei risultati migliori usando le strutture dati attualmente a disposizione, si è pensato di sfruttare le reti neurali per predire la posizione di un elemento all'interno di una lista; in questo caso il tempo di accesso sarebbe $O(1)$, ossia costante. \\
Per questo problema sono stati utilizzati tre dataset, rispettivamente con $512$, $8192$ e $1048576$ esempi. Le feature sono state rappresentate in codifica binaria e rappresentano gli elementi della lista, mentre i target sono i rispettivi valori della funzione di ripartizione empirica della loro distribuzione.
Il problema si pone il seguente quesito: data una lista di interi ordinata e un intero $x$, predire l'indice del predecessore di $x$. In questa versione si considereranno solamente valori di $x$ già presenti nella lista e il problema non si occuperà di operazioni di aggiornamento della lista quali inserimento ed eliminazione.
Il problema viene affrontato addestrando la rete ad associare ad ogni elemento della lista il valore della sua funzione di ripartizione empirica in modo poi da essere in grado di ottenere l'indice del predecessore tramite la formula \eqref{empirical}. 
\begin{equation}
\lceil\hat{F}(x)\times n\rceil
\label{empirical}
\end{equation}

\section{Architettura della rete}\label{architettura}
La prima rete considerata è stata costruita sfruttando delle API di Keras \footnote{https://keras.io/models/model/}. La rete è composta da uno strato di input con un numero di neuroni pari al numero di feature considerate, uno strato hidden con $n$ neuroni e uno strato di output con un singolo neurone. Per gli iper-parametri si è deciso di fissare learning rate, numero di epoche, batch size e funzione d'attivazione; per trovare il numero di neuroni per il singolo strato hidden, invece, si è usata una tecnica di model selection, modalità descritta al Paragrafo \ref{crossvalidation}.

Per il secondo problema sono state usate tre reti differenti:
\begin{itemize}
\item{rete 1 con 0 strati hidden};
\item{rete 2 con 1 strato hidden di 256 neuroni};
\item{rete 3 con 2 strati hidden di 256 neuroni ciascuno}.
\end{itemize}

Per tutte e tre le versioni gli iperparametri usati sono:
\begin{itemize}
\item{momentum update}\footnote{valore che è compreso tra 0 e 1 che velocizza la discesa del gradiente verso il minimo globale ~\cite{Momentum}}: $0.9$;
\item{$\lambda$}\footnote{usato per nella regolarizzazione l2, valore aggiunto alla loss function che forza pesi a scalare, penalizzando i pesi più grandi, riducendo così il problema di overfitting ~\cite{L2}}: $10^{-5}$;
\item{batch size}: $64$;
\item{epoche}: $20000$
\item{stop function}: vengono fissate due soglie, $s_1$ e $s_2$; l'apprendimento termina quando il valore della loss function non supera $s_1$ per $s_2$ volte consecutive.
\end{itemize}
Per la rete 1 è stato usato un learning rate di $5 \times 10^{-4}$, mentre per le altre due di $3 \times 10^{-3}$

\subsection{Oragnizzazione dei dati}
Per quanto riguarda il dataset di fifa, una volta mescolati gli esempi randomicamente, sono stati estratti l'80\% degli esempi come training set e il restante 20\% per il testing set. Inoltre entrambi i set sono stati ulteriormente divisi in X\_train e X\_test (contenente solo le colonne di feature) e y\_train e y\_test (contenente solo il target, cioè “Value”). Ogni valore null all’interno dei set è stato poi sostituito con la media della relativa colonna e i valori scalati usando StandardScaler di sklearn che utilizza la formula \eqref{standardscaler}
\begin{equation}
z = \frac{x - u}{s}
\label{standardscaler}
\end{equation}
dove u è la media del campione e s è la deviazione standard del campione.

Per il secondo dataset vengono usati tutti gli esempi nel training, dopo essere stati permutati randomicamente, come feature; i target invece vengono ricavati tramite la funzione numpy linspace che, dati i due estremi $s$ e $e$ di un intervallo e un intero $x$, restituisce un array di $x$ valori ordinati equamente spaziati compresi tra $s$ ed $e$.

\subsection{Addrestramento}
Per scegliere il giusto numero di neuroni per lo strato hidden si è proceduto con una cross-validation (Paragrafo \ref{crossvalidation}). Di seguito vengono riportati gli iper-parametri scelti per la rete:
\begin{itemize}
\item{funzione d’attivazione}:

\begin{itemize}
\item{ReLu 
\footnote{$f(x) =
\bigg \{
\begin{array}{rl}
x & x > 0 \\
0 & x \leq 0 \\
\end{array}
$
} per i neuroni dello strato hidden};
\item{lineare per il neurone d'output};
\end{itemize}

\item{loss function}: errore medio quadratico \footnote{
$\displaystyle{\frac{\sum_{i=1}^n \left(x_i - y_i\right)^2}{n}} \; \textit{dove x è l'i-esimo valore predetto, y è l'i-esimo target}$
};

\item{ottimizzatore}: Adam (componente Keras) con

\begin{itemize}
\item{learning rate}: 0.001;
\item{beta\_1}: 0.9;
\item{beta\_2}: 0.99;
\item{decay}: 0.0;
\end{itemize}

\item{numero epoche}: 100;

\item{batch size}: 64 esempi.
\end{itemize}

Il numero di fold esterni è stato impostato a 5, provando per l'unico hidden layer un numero di neuroni $n \in \{10, 20, 30, \dots, 200\}$.

\section{Risultati}

\subsection{Rete Keras}

I risultati migliori per singolo fold, considerando tutte le feature, sono riportati in tabella \ref{keras_all} 

\begin{table}[H]
\begin{center}
\begin{tabular}{lcr}
\toprule
Fold & Accuracy & Neurons \\
\midrule
1 & 0.9937 & 190\\
2 & 0.9938 & 180\\
3 & 0.9934 & 180\\
4 & 0.9920 & 180\\
5 & 0.9928 & 190\\
\bottomrule
\end{tabular}
\end{center}
\caption{Numero di neuroni strato hidden $n \in \{10, \dots, 200 \}$}
\label{keras_all}
\end{table}

\begin{table}[H]
\begin{center}
\begin{tabular}{lcr}
\toprule
Accuracy & Mean Error & Neurons \\
\midrule
0.9933 & 108251 & 180\\
\bottomrule
\end{tabular}
\end{center}
\caption{Risultato test con 180 neuroni e tutte le feature}
\label{keras_all_test}
\end{table}

\newpage

I risultati migliori per singolo fold, considerando solo le feature con correlazione superiore a 0.55, sono riportati in tabella \ref{keras_corr}

\begin{table}[H]
\begin{center}
\begin{tabular}{lcr}
\toprule
Fold & Accuracy & Neurons \\
\midrule
1  & 0.9723 & 200\\
2  & 0.9691 & 160\\
3  & 0.9696 & 200\\
4  & 0.9801 & 180\\
5  & 0.9698 & 190\\
\bottomrule
\end{tabular}
\end{center}
\caption{Numero di neuroni strato hidden $n \in \{10, \dots, 200 \}$}
\label{keras_corr}
\end{table}

\par\null\par
\par\null\par

I risultati migliori per singolo fold, considerando le feature selezionate con PCA, sono riportati in tabella \ref{keras_pca}

\begin{table}[H]
\begin{center}
\begin{tabular}{lcr}
\toprule
Fold & Accuracy & Neurons \\
\midrule
1 & 0.9955 & 200\\
2 & 0.9947 & 160\\
3 & 0.9955 & 190\\
4 & 0.9948 & 140\\
5 & 0.9944 & 180\\
\bottomrule
\end{tabular}
\end{center}
\caption{Numero di neuroni strato hidden $n \in \{10, \dots, 200 \}$}
\label{keras_pca}
\end{table}

\begin{table}[H]
\begin{center}
\begin{tabular}{lcr}
\toprule
Accuracy & Mean Error & Neurons \\
\midrule
0.9927 & 112081 & 200\\
\bottomrule
\end{tabular}
\end{center}
\caption{Risultato test con 200 neuroni e feature selezionate tramite PCA}
\label{keras_pca_test}
\end{table}

\par\null\par

Osservato il risultato migliore in corrispondenza del numero massimo di neuroni si è deciso di inserire un ulteriore strato hidden riducendo l'intervallo di neuroni in fase di cross validation, da 10 a 40.
Inoltre si è deciso di proseguire considerando tutte le feature e quelle selezionate tramite PCA.

I risultati migliori per singolo fold, considerando tutte le feature, sono riportati in tabella \ref{keras_all_2h}

\par\null\par

\begin{table}[H]
\begin{center}
\begin{tabular}{lcr}
\toprule
Fold & Accuracy & Neurons \\
\midrule
1 & 0.9960 & 70, 90\\
2 & 0.9961 & 100, 80\\
3 & 0.9962 & 100, 90\\
4 & 0.9959 & 80, 80\\
5 & 0.9961 & 90, 70\\
\bottomrule
\end{tabular}
\end{center}
\caption{Numero di neuroni strati hidden $n \in \{10, \dots, 100 \}$}
\label{keras_all_2h}
\end{table}

\begin{table}[H]
\begin{center}
\begin{tabular}{lcr}
\toprule
Accuracy & Mean Error & Neurons \\
\midrule
0.9945 & 98218 & 100, 90\\
\bottomrule
\end{tabular}
\end{center}
\caption{Risultato test con (100, 90) neuroni e tutte le feature}
\label{keras_all_test_2h}
\end{table}

I risultati migliori per singolo fold, considerando le feature selezionate tramite PCA, sono riportati in tabella \ref{keras_pca_2h}

\par\null\par
\begin{table}[H]
\begin{center}
\begin{tabular}{lcr}
\toprule
Fold & Accuracy & Neurons \\
\midrule
1 & 0.9964 & 100, 90\\
2 & 0.9962 & 100, 90\\
3 & 0.9964 & 80, 100\\
4 & 0.9962 & 100, 100\\
5 & 0.9963 & 100, 60\\
\bottomrule
\end{tabular}
\end{center}
\caption{Numero di neuroni strati hidden $n \in \{10, \dots, 100 \}$}
\label{keras_pca_2h}
\end{table}

\begin{table}[H]
\begin{center}
\begin{tabular}{lcr}
\toprule
Accuracy & Mean Error & Neurons \\
\midrule
0.9935 & 102477 & 80, 100\\
\bottomrule
\end{tabular}
\end{center}
\caption{Risultato test con (80, 100) neuroni e le feature selezionate tramite PCA}
\label{keras_pca_test_2h}
\end{table}

\par\null\par
\par\null\par

\subsection{Rete ad hoc}\label{reteAdHoc}
Purtroppo la rete costruita usando le API di Keras non si presta alla manipolazione necessaria per la compressione, né per il pruning, non c’è modo per mantenere inattive le connessioni tagliate, né per il weight sharing, non c’è compatibilità con le nuove strutture dati necessarie alla tecnica stessa.
Come per la rete precedente si sono usati gli stessi iper-parametri eccezion fatta per il numero di neuroni degli strati nascosti: per questi si è proceduto con una cross-validation i cui risultati sono riportati nelle tabelle \ref{hoc2_10_40} e \ref{hoc2_10_100}
\par\null\par
\begin{table}[H]
\begin{center}
\begin{tabular}{lcr}
\toprule
Fold & Accuracy & Neurons \\
\midrule
1 & 0.9946 & 30, 30\\
2 & 0.9959 & 40, 40\\
3 & 0.9958 & 40, 30\\
4 & 0.9953 & 40, 40\\
5 & 0.9955 & 40, 40\\
\bottomrule
\end{tabular}
\end{center}
\caption{Numero di neuroni strati hidden $n \in \{10, \dots, 40 \}$}
\label{hoc2_10_40}
\end{table}

\begin{table}[H]
\begin{center}
\begin{tabular}{lcr}
\toprule
Accuracy & Mean Error & Neurons \\
\midrule
0.9933 & 113366 & 40, 40\\
\bottomrule
\end{tabular}
\end{center}
\caption{Risultato test con (40, 90) neuroni e tutte le feature}
\label{hoc_all_test_40}
\end{table}

\newpage

\begin{table}[H]
\begin{center}
\begin{tabular}{lcr}
\toprule
Fold & Accuracy & Neurons \\
\midrule
1 & 0.9958 & 80, 90\\
2 & 0.9963 & 100, 80\\
3 & 0.9961 & 100, 90\\
4 & 0.9952 & 80, 90\\
5 & 0.9963 & 90, 90\\
\bottomrule
\end{tabular}
\end{center}
\caption{Numero di neuroni strati hidden $n \in \{10, \dots, 100 \}$}
\label{hoc2_10_100}
\end{table}

\begin{table}[H]
\begin{center}
\begin{tabular}{lcr}
\toprule
Accuracy & Mean Error & Neurons \\
\midrule
0.9938 & 102742 & 90, 90\\
\bottomrule
\end{tabular}
\end{center}
\caption{Risultato test con (90, 90) neuroni e tutte le feature}
\label{hoc_all_test_100}
\end{table}

\newpage

\subsection{Rete ad hoc per il problema del predecessore}
In questo paragrafo vengono riportati i risultati sull'argomento principale di questo elaborato.
La struttura della rete è quella presentata nel Paragrafo \ref{architettura} e i tre file utilizzati contengono rispettivamente 512, 8192 e 1048576 esempi.
Per ogni tabella riportata la prima riga indica i risultati ottenuti dalla rete ad hoc non compressa, in modo da poter effetture un confronto con le righe successive indicanti i risultati di pruning e weight sharing.

\subsection{Pruning rete ad hoc}
In questo paragrafo verranno illustrati i risultati ottenuti comprimendo la rete utilizzata nel sottoparagrafo \ref{reteAdHoc} con la tecnica del pruning.
Di seguito vengono spiegati i valori delle colonne.
\begin{itemize}
\item{pruning}: percentuale di connessioni eliminate; il valore 0 indica la rete non compressa;
\item{space overhead}: la frazione di spazio usata dalla rete per memorizzare l'indice rispetto alla dimensione del dataset misurato in kilobytes;
\item{training time}: tempo in secondi impiegato dalla rete per il training dopo la compressione;
\item{$\epsilon$}: errore massimo in fase di retraining;
\item{error \%}: errore massimo rispetto alla dimensione del dataset considerato;
\item{mean error}: errore medio.
\end{itemize}
\par\null\par
\par\null\par

\input{risultati_pruning}

\newpage

\subsection{Weight sharing rete ad hoc}
\begin{itemize}
\item{$\eta$}: proporzione dello spazio originario occupato da quella compressa; il valore 0 indica la rete non compressa $$\eta=\left(\frac{n m \times f(k) + 32k}{32 \times n m}\right)$$ 
\begin{multline}
$$dove \,\,\,\,\,
f(k) =
\bigg \{
\begin{array}{rl}
16 & nm > 256 \\
8 & altrimenti, \\
\end{array}
\begin{array}{ll}
k = numero\, di\, centroidi, \\
n, m = dimensione\, delle\, matrici
\end{array}
$$;
\end{multline}
\item{clusters}: indica, per ogni matrice dei pesi della rete, il numero di clusters utilizzati;
\item{space overhead}: la frazione di spazio usata dalla rete per memorizzare l'indice rispetto alla dimensione del dataset misurato in kilobytes;
\item{training time}: tempo in secondi impiegato dalla rete per il training dopo la compressione;
\item{$\epsilon$}: errore massimo in fase di retraining;
\item{error \%}: errore massimo rispetto alla dimensione del dataset considerato;
\item{mean error}: errore medio;
\end{itemize}
\par\null\par
\par\null\par

SPIEGARE PERCHÉ SI È COMINCIATO DA ETA 60 E NON 30, COME QUELLA CON 0 HIDDEN, O 10!

\input{risultati_ws}

\chapter{Conclusioni}
In questo elaborato si è affrontato il problema di come comprimere una rete neurale usata per fare regressione impatti su diversi aspetti della stessa, principalmente sul trade off tra accuratezza e dimensione occupata in memoria. Si è partiti da un caso particolare di regressione, la previsione del valore di mercato di giocatori di calcio, permettendo la comprensione della struttura di una rete neurale adatta a trattare tale problema. Una volta osservati i risultati ottenuti si è passati al problema del predecessore decidendo di affrontarlo usando tre diversi modelli di rete; a zero, singolo e doppio strato nascosto. Dai risultati ottenuti si può evincere che, sia con la tecnica di pruning che weight sharing, si ottengono dei buoni risultati considerando il rapporto accuratezza e memoria occupata. In particolare si può notare che eliminando fino al 60\% di connessioni tramite pruning si continua ad ottenere un errore massimo e medio inferiore alla rete originaria, il che si può leggere anche come un risparmio fino a più della metà dello spazio occupato dalle matrici della rete. C'è tuttavia da considerare anche il fattore tempo; usare una struttura dati come le matrici sparse richiede più tempo in fase di training in quanto le operazioni di moltiplicazione tra CSC diventano più dispendiose in termini di tempo. Ciònonostante questa problematica si presenta in fase di training, tempo che può essere ammortizzato su tutte le più numerose operazioni di previsione che si richiederanno alla rete.
Anche la tecnica di weight sharing ha dato ottimi risultati: infatti, escludendo il caso della rete senza strati nascosti, la rete compressa ha sempre dato risultati migliori o uguali in termini di errore medio, massimo e percentuale rispetto a quella originale. Si ripropone un pattern simile a quello del pruning; sono state ottenute delle reti con accuratezza simile o addirittura migliori come accuracy e meno onerose in termini di memoria ma con un training time più lungo, anche in questo caso dato dalle strutture dati impiegate (per le moltiplicazioni matriciali bisogna, per ogni elemento, accedere al relativo centroide, avendo quindi un doppio accesso), ma anche in questo caso il tempo di addestramento è ammortizzabile.
In conclusione, il raggiungimento dell'obiettivo di ridurre la memoria necessaria ad una rete neurale per fare regressione consente a queste ultime di essere utilizzate anche su macchine con ridotte quantità di memoria e di computazione, nonché di un ridotto consumo di risorse energetiche e computazionali. 

\bibliography{bibliography}{}
\bibliographystyle{unsrt}

\end{document}
